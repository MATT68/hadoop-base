Para configurar Hadoop debemos ir preparando varios ficheros:

1.- Descargar Java y descomprimirlo   en /usr/java

2.- Descargar Hadoop y descomprimirlo en /usr/local/hadoop
    Cambiar el propietario al directorio  /usr/local/hadoop
	
3.- Descargar librerías necesarias: ssh, rsync, etc.

4.- Definir variables de entorno. 
    Si es directo en linux:
	  Editar el ~/.bashrc y añadir las variables:
	En dockerfile definimos variables con ENV.
	
5.- Configurar ssh para conexiones sin password. Arrancar el servicio ssh.
    
6.- Configurar /var/log

7.- Configurar los ficheros de Hadoop.
    En el directorio /usr/local/hadoop/etc/hadoop debemos tener: 
	core-site.xml
	mapred-site.xml.template
	hdfs-site.xml
	yarn-site.xml

Contenido de los ficheros:
	
core-site.xml
<configuration>
   <property>
       <name>fs.defaultFS</name>
       <value>hdfs://localhost:9000</value>
   </property>
</configuration>

Copiamos mapred-site.xml.template en mapred-site.xml y editamos:
	
mapred-site.xml   
<configuration>
   <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
   </property>
</configuration>	

Debemos crear los directorios : 
/usr/local/hadoop/data/namenode
/usr/local/hadoop/data/datanode
Y luego podemos editar el siguiente fichero:
(Como tenemos un pseudo cluster no tiene sentido indicar un factor de
replicación mayor de 1)

hdfs-site.xml
<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	
	<configuration>
	  <property>
	    <name>dfs.namenode.name.dir</name>
	    <value>file:/home/hadoop/workspace/dfs/name</value>
	    <description>/usr/local/hadoop/data/namenode</description>
	  </property>
 
	  <property>
	    <name>dfs.datanode.data.dir</name>
	    <value>file:/home/hadoop/workspace/dfs/data</value>
	    <description>/usr/local/hadoop/data/datanode</description>
	  </property>
 
	  <property>
	      <name>dfs.replication</name>
	      <value>1</value>
	      <description>Factor de replicación. Lo ponemos a 1 porque sólo tenemos 1 máquina.</description>
	  </property>
	</configuration>
	

yarn-site.xml
<configuration>
   <property>
    	<name>yarn.nodemanager.aux-services</name>
    	<value>mapreduce_shuffle</value>
   </property>
   <property>
      	<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>  
	<value>org.apache.hadoop.mapred.ShuffleHandler</value>
   </property>
</configuration>